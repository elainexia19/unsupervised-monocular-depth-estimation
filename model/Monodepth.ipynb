{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easydict import EasyDict as edict\n",
    "\n",
    "from main_monodepth_pytorch import Model\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if CUDA is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_parameters = edict({'data_dir':'Z:/DL_Project/data',\n",
    "                         'val_data_dir':'Z:/DL_Project/data',\n",
    "                         'model_path':'Z:/DL_Project/monodepth_resnet18_002_cpt.pth', \n",
    "                         'output_directory':'Z:/DL_Project/output_18_002',\n",
    "                         'input_height':256,\n",
    "                         'input_width':512,\n",
    "                         'model':'resnet18_md',\n",
    "                         'pretrained':True,\n",
    "                         'mode':'train',\n",
    "                         'epochs':50,\n",
    "                         'learning_rate':1e-4,\n",
    "                         'batch_size': 8,\n",
    "                         'adjust_lr':True,\n",
    "                         'device':'cuda:0',\n",
    "                         'do_augmentation':True,\n",
    "                         'augment_parameters':[0.8, 1.2, 0.5, 2.0, 0.8, 1.2],\n",
    "                         'print_images':False,\n",
    "                         'print_weights':False,\n",
    "                         'input_channels': 3,\n",
    "                         'num_workers': 8,\n",
    "                         'use_multiple_gpu': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(dict_parameters)\n",
    "model.load('Z:/DL_Project/monodepth_resnet50_002_last.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_parameters_test = edict({'data_dir':'Z:/DL_Project/xxx',\n",
    "                              'model_path':'Z:/DL_Project/monodepth_resnet18_001_cpt.pth',\n",
    "                              'output_directory':'Z:/DL_Project/xxx/',\n",
    "                              'input_height':256,\n",
    "                              'input_width':512,\n",
    "                              'model':'resnet50_md',\n",
    "                              'pretrained':False,\n",
    "                              'mode':'test',\n",
    "                              'device':'cuda:0',\n",
    "                              'input_channels':3,\n",
    "                              'num_workers':8,\n",
    "                              'use_multiple_gpu':False})\n",
    "model_test = Model(dict_parameters_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = np.load('Z:/DL_Project/xxx/disparities_pp.npy')  # Or disparities.npy for output without post-processing\n",
    "disp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp_to_img = skimage.transform.resize(disp[0].squeeze(), [375, 1242], mode='constant')\n",
    "plt.imshow(disp_to_img, cmap='plasma')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save a color image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imsave(os.path.join(dict_parameters_test.output_directory,\n",
    "                        dict_parameters_test.model_path.split('/')[-1][:-4]+'_test_output.png'), disp_to_img, cmap='plasma')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save all test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(disp.shape[0]):\n",
    "    disp_to_img = skimage.transform.resize(disp[i].squeeze(), [375, 1242], mode='constant')\n",
    "    plt.imsave(os.path.join(dict_parameters_test.output_directory,\n",
    "               'pred_'+str(i)+'.png'), disp_to_img, cmap='plasma')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save a grayscale image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imsave(os.path.join(dict_parameters_test.output_directory,\n",
    "                        dict_parameters_test.model_path.split('/')[-1][:-4]+'_gray.png'), disp_to_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width_to_focal = dict()\n",
    "width_to_focal[1242] = 721.5377\n",
    "width_to_focal[1241] = 718.856\n",
    "width_to_focal[1224] = 707.0493\n",
    "width_to_focal[1238] = 718.3351\n",
    "def load_gt_disp_kitti(path):\n",
    "    gt_disparities = []\n",
    "    for i in range(97):\n",
    "        disp = cv2.imread(path + str(i+5).zfill(10) + \".png\", -1)\n",
    "        print(disp)\n",
    "        disp = disp.astype(np.float32) / 256\n",
    "        gt_disparities.append(disp)\n",
    "    return gt_disparities\n",
    "\n",
    "def compute_errors(gt, pred):\n",
    "    thresh = np.maximum((gt / pred), (pred / gt))\n",
    "    a1 = (thresh < 1.25   ).mean()\n",
    "    a2 = (thresh < 1.25 ** 2).mean()\n",
    "    a3 = (thresh < 1.25 ** 3).mean()\n",
    "\n",
    "    rmse = (gt - pred) ** 2\n",
    "    rmse = np.sqrt(rmse.mean())\n",
    "\n",
    "    rmse_log = (np.log(gt) - np.log(pred)) ** 2\n",
    "    rmse_log = np.sqrt(rmse_log.mean())\n",
    "\n",
    "    abs_rel = np.mean(np.abs(gt - pred) / gt)\n",
    "\n",
    "    sq_rel = np.mean(((gt - pred)**2) / gt)\n",
    "\n",
    "    return abs_rel, sq_rel, rmse, rmse_log, a1, a2, a3\n",
    "def convert_disps_to_depths_kitti(gt_disparities, pred_disparities):\n",
    "    gt_depths = []\n",
    "    pred_depths = []\n",
    "    pred_disparities_resized = []\n",
    "    \n",
    "    for i in range(len(gt_disparities)):\n",
    "        gt_disp = gt_disparities[i]\n",
    "        height, width = gt_disp.shape\n",
    "\n",
    "        pred_disp = pred_disparities[i]\n",
    "        pred_disp = width * cv2.resize(pred_disp, (width, height), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        pred_disparities_resized.append(pred_disp) \n",
    "\n",
    "        mask = gt_disp > 0\n",
    "\n",
    "        gt_depth = width_to_focal[width] * 0.54 / (gt_disp + (1.0 - mask))\n",
    "        pred_depth = width_to_focal[width] * 0.54 / pred_disp\n",
    "\n",
    "        gt_depths.append(gt_depth)\n",
    "        pred_depths.append(pred_depth)\n",
    "    return gt_depths, pred_depths, pred_disparities_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_disparities = np.load(\"Z:/DL_Project/xxx/disparities_pp.npy\")\n",
    "gt_disparities = load_gt_disp_kitti(\"Z:/DL_Project/test/2011_09_26_drive_0001_sync/proj_depth/groundtruth/image_02/\")\n",
    "gt_depths, pred_depths, pred_disparities_resized = convert_disps_to_depths_kitti(gt_disparities, pred_disparities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples=97\n",
    "rms     = np.zeros(num_samples, np.float32)\n",
    "log_rms = np.zeros(num_samples, np.float32)\n",
    "abs_rel = np.zeros(num_samples, np.float32)\n",
    "sq_rel  = np.zeros(num_samples, np.float32)\n",
    "d1_all  = np.zeros(num_samples, np.float32)\n",
    "a1      = np.zeros(num_samples, np.float32)\n",
    "a2      = np.zeros(num_samples, np.float32)\n",
    "a3      = np.zeros(num_samples, np.float32)\n",
    "for i in range(num_samples):\n",
    "        \n",
    "    gt_depth = gt_depths[i]\n",
    "    pred_depth = pred_depths[i]\n",
    "    min_depth=1e-3\n",
    "    max_depth=80\n",
    "    pred_depth[pred_depth < min_depth] = min_depth\n",
    "    pred_depth[pred_depth > max_depth] = max_depth\n",
    "        \n",
    "    gt_disp = gt_disparities[i]\n",
    "    \n",
    "    mask = gt_disp > 0\n",
    "    pred_disp = pred_disparities_resized[i]\n",
    "\n",
    "    disp_diff = np.abs(gt_disp[mask] - pred_disp[mask])\n",
    "    bad_pixels = np.logical_and(disp_diff >= 3, (disp_diff / gt_disp[mask]) >= 0.05)\n",
    "    d1_all[i] = 100.0 * bad_pixels.sum() / mask.sum()\n",
    "\n",
    "    abs_rel[i], sq_rel[i], rms[i], log_rms[i], a1[i], a2[i], a3[i] = compute_errors(gt_depth[mask], pred_depth[mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"{:>10}, {:>10}, {:>10}, {:>10}, {:>10}, {:>10}, {:>10}, {:>10}\".format('abs_rel', 'sq_rel', 'rms', 'log_rms', 'd1_all', 'a1', 'a2', 'a3'))\n",
    "print(\"{:10.4f}, {:10.4f}, {:10.3f}, {:10.3f}, {:10.3f}, {:10.3f}, {:10.3f}, {:10.3f}\".format(abs_rel.mean(), sq_rel.mean(), rms.mean(), log_rms.mean(), d1_all.mean(), a1.mean(), a2.mean(), a3.mean()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
